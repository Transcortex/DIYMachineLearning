
# DIYMachineLearning YouTube Series - Episode 10 Script (Word-for-Word)

## Episode 10: Evaluating Your Image Classifier Model

---

### 00:00 - 00:30 | Introduction
- **Script:** "Welcome back to DIYMachineLearning! Now that we’ve built our first image classifier, it’s time to evaluate its performance. Evaluating helps us see how well our model is learning and where it needs improvement."

---

### 00:30 - 03:00 | Loading the Model and Test Data
- **Script:** "First, load the trained model and some test data that the model hasn’t seen before. This lets us measure how well it performs on new data."

---

### 03:00 - 05:30 | Evaluating Model Accuracy
- **Script:** "Let’s start with accuracy, which shows the percentage of correct predictions. Use the model’s `evaluate` function to see the test accuracy and loss values."

---

### 05:30 - 07:30 | Precision, Recall, and F1 Score
- **Script:** "Besides accuracy, precision and recall give deeper insights. Precision tells us the percentage of true positives out of all positive predictions. Recall shows how many true positives were correctly identified. The F1 score combines both for a balanced view."

---

### 07:30 - 09:00 | Creating a Confusion Matrix
- **Script:** "A confusion matrix shows the number of true positives, false positives, true negatives, and false negatives. It’s a detailed way to see how well the model handles each class."

---

### 09:00 - 10:00 | Reviewing Evaluation Results
- **Script:** "By reviewing accuracy, precision, recall, F1 score, and the confusion matrix, we get a full picture of model performance. If certain metrics are low, we know where to improve."

---

### Closing
- **Script:** "That’s it for evaluating our image classifier! Now we know where our model shines and where it needs work. In the next episode, we’ll look into ways to optimize it. Don’t forget to like, subscribe, and join us for more DIYMachineLearning!"

---
